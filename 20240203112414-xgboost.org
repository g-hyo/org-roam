:PROPERTIES:
:ID:       65d80cf7-80a7-4151-8a4b-145d97994519
:END:
#+title: xgboost

XGBoost (Extreme Gradient Boosting) is an open source software library which provides a gradient boosting framework for various programming languages.

* Algorithm

XGBoost works as a [[id:648c9790-5069-4b04-9973-c1b84863f812][Newton-Raphson method]] in function space (?)

** Prediction

The prediction of XGBoost is generated by a tree ensemble model which uses K additive functions to preduct the output.

F is the space of [[id:6bf8ab89-eb80-4e4e-b365-7ca4a8a4ce20][regression trees]].

For a given example, the final prediction is acquired by summing the score of the corresponding leaves in all the trees.

** Learning Objective

To learn the set of functions used in the model, a regularised objective is minimised composed of the sum of:

1. The sum of a differentiable convex loss function that measure the difference between predictions and targets
2. An `omega` function which penalises the complexity of the models `k`

The penalty term takes into account `T`, the number of leaves in the tree and `w`, the leaf weight or prediction

** Gradient Tree Boosting

The learning objective includes functions as parameters and cannot be optmized using traditional optimization methods in Euclidian space.

Instead, the model makes use of [[id:c3af5c6d-003d-4d4d-9a1d-020a63551d1e][gradient tree boosting]] to add trees.

* References

[Original paper](https://arxiv.org/abs/1603.02754)
